{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL-Pipeline for US Immigration Data\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline that ultimately creates a star schema with a fact table describing immigration data for the US. Dimensional tables refer to time (immigration date) and multiple location (arrival state, arrival airport, country of origin) dimensions, and are enriched with additional data of interest.\n",
    "\n",
    "Based on the data aggregated in the star schema, one can submit analytical queries to gain insight about e.g.\n",
    "\n",
    "* temporal distribution of immigration events\n",
    "* demographic details of the arrival state and connections to immigration characteristics\n",
    "* connections between temperatures within origin countries and immigration details\n",
    "* which airports and airlines are used by immigrants\n",
    "\n",
    "The project exemplifies the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---\n",
    "**NOTE**: within this notebook, the project is only sketched, while a highly structured implementation of the ETL process can be found in the `etl` folder, containing the following files:\n",
    "\n",
    "| File       | Description |\n",
    "| -----------| ------------|\n",
    "| etl.py     | main module that can be executed from shell to run the pipeline |\n",
    "| config.py  | configuration of the etl process via pydantic |\n",
    "| etl_extract.py | data extraction functions and classes used within main module |\n",
    "| etl_load.py | data load functions and classes used within main module |\n",
    "| requirements.txt | package requirements to execute script |\n",
    "| config.json | default configuration in JSON format |\n",
    "\n",
    "The script can be started from shell via `python etl.py`. Different command-line arguments can be used: to get an overview, execute `python etl.py -h`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Sequence\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_nan_percent(df: pd.DataFrame, cols: Sequence[str]) -> pd.DataFrame:\n",
    "\n",
    "    info = {}\n",
    "    len_df = float(len(df))\n",
    "    for col_name in cols:\n",
    "        na_ratio = len(df[df[col_name].isna() == True])/len_df\n",
    "        info[col_name] = na_ratio * 100.0\n",
    "\n",
    "    df_out = pd.DataFrame.from_dict({\"Column\": list(info.keys()), \"Percent_NaN\": list(info.values())})\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The first step is to describe the provided data and load it into this notebook in order to perform initial checks and to gain insights.\n",
    "\n",
    "For smaller files, it will be sufficient to use standard **pandas** functions, while **pyspark** will be employed for processing larger files.\n",
    "\n",
    "The following steps will be carried out:\n",
    "\n",
    "1. load data and describe formats\n",
    "2. perform exploratory data analysis in order to evaluate possible issues or find valuable insights\n",
    "3. clean data to achieve a high-qualty state for further processing\n",
    "4. outline the ETL process and define the target schema\n",
    "5. create actual fact and dimension tables\n",
    "6. possibly upload/dump the resulting schema into target system(s)\n",
    "\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "In the following, the source data will be described and loaded into objects within the notebook for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1. Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Description**: contains average temperatures for a variety of cities along the time axis. Additional spatio-geographical information is included.\n",
    "\n",
    "Source: https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data (Kaggle)\n",
    "\n",
    "Table structure:\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| dt                   | datetime | record time  |\n",
    "| AverageTemperature   | float    | celsius      |\n",
    "| City                 | string   | city name    |\n",
    "| Country              | string   | country name |\n",
    "| Latitude             | string   | city latitude |\n",
    "| Longitude            | string   | city longitude |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data into pandas dataframe\n",
    "weather_data = Path(\"data/GlobalLandTemperaturesByCity_sample.csv\")\n",
    "df_wtr = pd.read_csv(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2. Airport Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Description**: contains identification characteristics and geographical information about airports.\n",
    "\n",
    "Source: https://datahub.io/core/airport-codes#data (DataHub)\n",
    "\n",
    "Table structure:\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| ident                | string   | airport identifier code            |\n",
    "| type                 | string   | airport type            |\n",
    "| elevation_ft         | float    | elevation in feet            |\n",
    "| continent            | string   | airport continent             |\n",
    "| iso_country          | string   | country ISO code             |\n",
    "| iso_region           | string   | region ISO code             |\n",
    "| municipality         | string   | name of municipality            |\n",
    "| gps_code             | string   | GPS code            |\n",
    "| iata_code            | string   | IATA code             |\n",
    "| local_code           | string   | local airport code            |\n",
    "| coordinates          | string   | tuple of latitude, longitude       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data into pandas dataframe\n",
    "airport_data = Path(\"data/airport-codes_csv.csv\")\n",
    "df_apt = pd.read_csv(airport_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3. Immigration Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Description**: contains information about individual immigration processes. Each row contains a set of records for an individuals' arrival in the US. All data in the set is from the year 2016 and is partitioned by months.\n",
    "    \n",
    "Source: https://travel.trade.gov/research/reports/i94/historical/2016.html (US National Tourism and Trade Office)\n",
    "    \n",
    "Table structure:\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| cicid                | float   |      record ID        |\n",
    "| i94yr                | float   |      year        |\n",
    "| i94mon               | float    |         month     |\n",
    "| i94cit               | float   |      birth country ID        |\n",
    "| i94res               | float   |      residence country ID        |\n",
    "| i94port              | string   |     arrival port in US        |\n",
    "| arrdate              | float   |      arrival date in US      |\n",
    "| i94mode              | float   |      transportation mode (air: 1, sea: 2, land: 3, else: 9)        |\n",
    "| i94addr              | string   |     arrival state         |\n",
    "| depdate              | float   |      departure date        |\n",
    "| i94bir               | float  | age       |\n",
    "| i94visa              | float   |   visa code           |\n",
    "| count                | float   |   auxiliary field           |\n",
    "| dtadfile             | string    |  auxiliary date field            |\n",
    "| visapost             | string   |   state of visa grant           |\n",
    "| occup                | string   |   occupation in US           |\n",
    "| entdepa              | string   |   arrival code           |\n",
    "| entdepd              | string   |   departure code           |\n",
    "| entdepu              | string   |   update code           |\n",
    "| matflag              | string   |   matching code            |\n",
    "| biryear              | float   |    birth year          |\n",
    "| dtaddto              | string  | residence allowance date        |\n",
    "| gender               | string   |  gender            |\n",
    "| insnum               | string    |  INS number            |\n",
    "| airline              | string   |  airline for arrival            |\n",
    "| admnum               | float   |   admission number           |\n",
    "| fltno                | string   |  flight number            |\n",
    "| visatype             | string   |  type of visa            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize spark session \n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Load data into spark dataframe\n",
    "# dfsp_imgn_apr = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "dfsp_imgn_apr = spark.read.option(\"header\", True).csv(\"data/immigration_data_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4. City demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Description**: contains demographic data about US cities, where each city & state entry is partitioned by race.\n",
    "\n",
    "Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/ (OpenSoft)\n",
    "\n",
    "Table structure:\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| City                | string   |      city name        |\n",
    "| State                 | string   |    state name          |\n",
    "| Median Age           | float    |     median resident age         |\n",
    "| Male Population       | float   |     total number of male residents         |\n",
    "| Female Population       | float   |   total number of female residents           |\n",
    "| Total Population        | int   |     total population number         |\n",
    "| Number of Veterans       | float   |  number of veterans           |\n",
    "| Foreign born             | float   |  number of foreign born residents            |\n",
    "| Average Household Size    | float   |   average number of people in households           |\n",
    "| State Code                | string   |    2-character US state code          |\n",
    "| Race                      | string  |  race for next column       |\n",
    "| Count                 | int  | number of residents of race defined in former column       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load data into pandas dataframe\n",
    "city_data = Path(\"data/us-cities-demographics.csv\")\n",
    "df_cities = pd.read_csv(city_data, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "##### 1. Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 rows\n",
    "df_wtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100295 entries, 0 to 100294\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   dt                             100295 non-null  object \n",
      " 1   AverageTemperature             96020 non-null   float64\n",
      " 2   AverageTemperatureUncertainty  96020 non-null   float64\n",
      " 3   City                           100295 non-null  object \n",
      " 4   Country                        100295 non-null  object \n",
      " 5   Latitude                       100295 non-null  object \n",
      " 6   Longitude                      100295 non-null  object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get general data info\n",
    "df_wtr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique city/country fields just out of interest\n",
    "len(df_wtr[\"City\"].unique()), len(df_wtr[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate rows (with respect to relevant tuples) - there are many duplicates!\n",
    "len(df_wtr[df_wtr.duplicated(subset=[\"dt\", \"City\", \"Country\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Column  Percent_NaN\n",
      "0                             dt     0.000000\n",
      "1             AverageTemperature     4.262426\n",
      "2  AverageTemperatureUncertainty     4.262426\n",
      "3                           City     0.000000\n",
      "4                        Country     0.000000\n",
      "5                       Latitude     0.000000\n",
      "6                      Longitude     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - relatively well-conditioned ...! However, rows without a temperature are useless.\n",
    "print(get_nan_percent(df_wtr, list(df_wtr.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Airport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 rows\n",
    "df_apt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# General dataframe info\n",
    "df_apt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Column  Percent_NaN\n",
      "0          ident     0.000000\n",
      "1           type     0.000000\n",
      "2           name     0.000000\n",
      "3   elevation_ft    12.720835\n",
      "4      continent    50.329551\n",
      "5    iso_country     0.448479\n",
      "6     iso_region     0.000000\n",
      "7   municipality    10.305946\n",
      "8       gps_code    25.501589\n",
      "9      iata_code    83.315479\n",
      "10    local_code    47.914662\n",
      "11   coordinates     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - continent, iata_code, local code have over 40% missing values, rest is quite OK!\n",
    "print(get_nan_percent(df_apt, list(df_apt.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3. Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|      x|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|       admnum|fltno|visatype|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "|2027561|4084316.0|2016.0|   4.0| 209.0| 209.0|    HHW|20566.0|    1.0|     HI|20573.0|  61.0|    2.0|  1.0|20160422|    null| null|      G|      O|   null|      M| 1955.0|07202016|     F|  null|     JL|56582674633.0|00782|      WT|\n",
      "|2171295|4422636.0|2016.0|   4.0| 582.0| 582.0|    MCA|20567.0|    1.0|     TX|20568.0|  26.0|    2.0|  1.0|20160423|     MTR| null|      G|      R|   null|      M| 1990.0|10222016|     M|  null|    *GA|94361995930.0|XBLNG|      B2|\n",
      "| 589494|1195600.0|2016.0|   4.0| 148.0| 112.0|    OGG|20551.0|    1.0|     FL|20571.0|  76.0|    2.0|  1.0|20160407|    null| null|      G|      O|   null|      M| 1940.0|07052016|     M|  null|     LH|55780468433.0|00464|      WT|\n",
      "|2631158|5291768.0|2016.0|   4.0| 297.0| 297.0|    LOS|20572.0|    1.0|     CA|20581.0|  25.0|    2.0|  1.0|20160428|     DOH| null|      G|      O|   null|      M| 1991.0|10272016|     M|  null|     QR|94789696030.0|00739|      B2|\n",
      "|3032257| 985523.0|2016.0|   4.0| 111.0| 111.0|    CHM|20550.0|    3.0|     NY|20553.0|  19.0|    2.0|  1.0|20160406|    null| null|      Z|      K|   null|      M| 1997.0|07042016|     F|  null|   null|42322572633.0| LAND|      WT|\n",
      "+-------+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+-------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 rows\n",
    "dfsp_imgn_apr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the data schema\n",
    "dfsp_imgn_apr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split into 3 columns for better visibility within notebook; show summaries thereafter piece-by-piece\n",
    "col_parts = np.array_split(dfsp_imgn_apr.columns, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------+------+------------------+------------------+-------+-----------------+------------------+-------+\n",
      "|summary|                x|             cicid| i94yr|i94mon|            i94cit|            i94res|i94port|          arrdate|           i94mode|i94addr|\n",
      "+-------+-----------------+------------------+------+------+------------------+------------------+-------+-----------------+------------------+-------+\n",
      "|  count|             1000|              1000|  1000|  1000|              1000|              1000|   1000|             1000|              1000|    941|\n",
      "|   mean|       1542097.12|       3040461.409|2016.0|   4.0|           302.928|           298.262|   null|         20559.68|             1.078|   null|\n",
      "| stddev|915287.9043923795|1799817.7827726966|   0.0|   0.0|206.48528516334758|202.12038988683958|   null|8.995026987758733|0.4859548869516101|   null|\n",
      "|    min|          1006205|         1000074.0|2016.0|   4.0|             103.0|             103.0|    AGA|          20545.0|               1.0|     AL|\n",
      "|    25%|         721257.0|         1408683.0|2016.0|   4.0|             135.0|             131.0|   null|          20552.0|               1.0|   null|\n",
      "|    50%|        1494106.0|         2938927.0|2016.0|   4.0|             213.0|             213.0|   null|          20560.0|               1.0|   null|\n",
      "|    75%|        2360660.0|         4693164.0|2016.0|   4.0|             438.0|             438.0|   null|          20567.0|               1.0|   null|\n",
      "|    max|           997880|          999282.0|2016.0|   4.0|             746.0|             696.0|    X96|          20574.0|               9.0|     WI|\n",
      "+-------+-----------------+------------------+------+------+------------------+------------------+-------+-----------------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfsp_imgn_apr.select([col(c) for c in col_parts[0]]).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-----+-----------------+--------+-----+-------+-------+-------+\n",
      "|summary|           depdate|           i94bir|           i94visa|count|         dtadfile|visapost|occup|entdepa|entdepd|entdepu|\n",
      "+-------+------------------+-----------------+------------------+-----+-----------------+--------+-----+-------+-------+-------+\n",
      "|  count|               951|             1000|              1000| 1000|             1000|     382|    4|   1000|    954|      0|\n",
      "|   mean| 20575.03785488959|           42.382|             1.859|  1.0|   2.0160424879E7|    null| null|   null|   null|   null|\n",
      "| stddev|24.211233522000143|17.90342449389526|0.3863525181337226|  0.0|49.51656540286629|    null| null|   null|   null|   null|\n",
      "|    min|           20547.0|              1.0|               1.0|  1.0|         20160401|     ABD|  OTH|      A|      D|   null|\n",
      "|    25%|           20561.0|             30.0|               2.0|  1.0|      2.0160408E7|    null| null|   null|   null|   null|\n",
      "|    50%|           20570.0|             42.0|               2.0|  1.0|      2.0160416E7|    null| null|   null|   null|   null|\n",
      "|    75%|           20580.0|             55.0|               2.0|  1.0|      2.0160425E7|    null| null|   null|   null|   null|\n",
      "|    max|           20715.0|             93.0|               3.0|  1.0|         20160801|     WRW|  STU|      Z|      W|   null|\n",
      "+-------+------------------+-----------------+------------------+-----+-----------------+--------+-----+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfsp_imgn_apr.select([col(c) for c in col_parts[1]]).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+------------------+------+------------------+-------+--------------------+------------------+--------+\n",
      "|summary|matflag|          biryear|           dtaddto|gender|            insnum|airline|              admnum|             fltno|visatype|\n",
      "+-------+-------+-----------------+------------------+------+------------------+-------+--------------------+------------------+--------+\n",
      "|  count|    954|             1000|              1000|   859|                35|    967|                1000|               992|    1000|\n",
      "|   mean|   null|         1973.618| 8258277.404255319|  null|3826.8571428571427|    2.0|  6.9372367950789E10|1337.2554291623578|    null|\n",
      "| stddev|   null|17.90342449389525|1622586.3557888167|  null| 221.7425829858661|    0.0|2.338134181802248E10| 6149.954574383991|    null|\n",
      "|    min|      M|           1923.0|          04082018|     F|              3468|    *GA|                 0.0|             00001|      B1|\n",
      "|    25%|   null|           1961.0|         7092016.0|  null|            3668.0|    2.0|     5.5991897633E10|             100.0|    null|\n",
      "|    50%|   null|           1974.0|         7252016.0|  null|            3887.0|    2.0|     5.9313924133E10|             410.0|    null|\n",
      "|    75%|   null|           1985.0|       1.0122016E7|  null|            3943.0|    2.0|      9.343458123E10|             906.0|    null|\n",
      "|    max|      M|           2015.0|               D/S|     X|              4686|     ZX|       95021509030.0|             XBLNG|      WT|\n",
      "+-------+-------+-----------------+------------------+------+------------------+-------+--------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfsp_imgn_apr.select([col(c) for c in col_parts[2]]).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "n_rows = dfsp_imgn_apr.count()\n",
    "print(n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate identifiers - cicid is a unique row identifier!\n",
    "dfsp_imgn_apr.select(\"cicid\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+------+------+------+-------+-------+-------+------------------+\n",
      "|  x|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|           i94addr|\n",
      "+---+-----+-----+------+------+------+-------+-------+-------+------------------+\n",
      "|0.0|  0.0|  0.0|   0.0|   0.0|   0.0|    0.0|    0.0|    0.0|5.8999999999999995|\n",
      "+---+-----+-----+------+------+------+-------+-------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - quite OK in this selection!\n",
    "dfsp_imgn_apr.select([(count(when(isnan(c) | col(c).isNull(), c)) / n_rows * 100).alias(c) for c in col_parts[0]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+\n",
      "|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|\n",
      "+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+\n",
      "|    4.9|   0.0|    0.0|  0.0|     0.0|    61.8| 99.6|    0.0|    4.6|  100.0|\n",
      "+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - visapost, occup, entdepu have very high amounts of invalid entries!\n",
    "dfsp_imgn_apr.select([(count(when(isnan(c) | col(c).isNull(), c)) / n_rows * 100).alias(c) for c in col_parts[1]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+------------------+------+------------------+------+-----+--------+\n",
      "|matflag|biryear|dtaddto|            gender|insnum|           airline|admnum|fltno|visatype|\n",
      "+-------+-------+-------+------------------+------+------------------+------+-----+--------+\n",
      "|    4.6|    0.0|    0.0|14.099999999999998|  96.5|3.3000000000000003|   0.0|  0.8|     0.0|\n",
      "+-------+-------+-------+------------------+------+------------------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - insnum has very high amounts of invalid entries!\n",
    "dfsp_imgn_apr.select([(count(when(isnan(c) | col(c).isNull(), c)) / n_rows * 100).alias(c) for c in col_parts[2]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first 5 rows\n",
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   City                    2891 non-null   object \n",
      " 1   State                   2891 non-null   object \n",
      " 2   Median Age              2891 non-null   float64\n",
      " 3   Male Population         2888 non-null   float64\n",
      " 4   Female Population       2888 non-null   float64\n",
      " 5   Total Population        2891 non-null   int64  \n",
      " 6   Number of Veterans      2878 non-null   float64\n",
      " 7   Foreign-born            2878 non-null   float64\n",
      " 8   Average Household Size  2875 non-null   float64\n",
      " 9   State Code              2891 non-null   object \n",
      " 10  Race                    2891 non-null   object \n",
      " 11  Count                   2891 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print general info\n",
    "df_cities.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for relevant partitions - city+state+race correspond to unique rows\n",
    "len(df_cities[[\"City\", \"State\", \"Race\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Hispanic or Latino', 'White', 'Asian',\n",
       "        'Black or African-American', 'American Indian and Alaska Native'],\n",
       "       dtype=object),\n",
       " 2785)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities[\"Race\"].unique(), len(df_cities[\"Count\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70.5, 22.9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities[\"Median Age\"].max(), df_cities[\"Median Age\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>15231.0</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City    State  Median Age  Male Population  Female Population  \\\n",
       "333   The Villages  Florida        70.5              NaN                NaN   \n",
       "449   The Villages  Florida        70.5              NaN                NaN   \n",
       "1437  The Villages  Florida        70.5              NaN                NaN   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "333              72590             15231.0        4034.0   \n",
       "449              72590             15231.0        4034.0   \n",
       "1437             72590             15231.0        4034.0   \n",
       "\n",
       "      Average Household Size State Code                       Race  Count  \n",
       "333                      NaN         FL         Hispanic or Latino   1066  \n",
       "449                      NaN         FL  Black or African-American    331  \n",
       "1437                     NaN         FL                      White  72211  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities[df_cities[\"Median Age\"] == df_cities[\"Median Age\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Column  Percent_NaN\n",
      "0                     City     0.000000\n",
      "1                    State     0.000000\n",
      "2               Median Age     0.000000\n",
      "3          Male Population     0.103770\n",
      "4        Female Population     0.103770\n",
      "5         Total Population     0.000000\n",
      "6       Number of Veterans     0.449671\n",
      "7             Foreign-born     0.449671\n",
      "8   Average Household Size     0.553442\n",
      "9               State Code     0.000000\n",
      "10                    Race     0.000000\n",
      "11                   Count     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs/NULLs - everything is relatively OK!\n",
    "print(get_nan_percent(df_cities, list(df_cities.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MD', 'MA', 'AL', 'CA', 'NJ', 'IL', 'AZ', 'MO', 'NC', 'PA', 'KS',\n",
       "       'FL', 'TX', 'VA', 'NV', 'CO', 'MI', 'CT', 'MN', 'UT', 'AR', 'TN',\n",
       "       'OK', 'WA', 'NY', 'GA', 'NE', 'KY', 'SC', 'LA', 'NM', 'IA', 'RI',\n",
       "       'PR', 'DC', 'WI', 'OR', 'NH', 'ND', 'DE', 'OH', 'ID', 'IN', 'AK',\n",
       "       'MS', 'HI', 'SD', 'ME', 'MT'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities[\"State Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hispanic or Latino', 'White', 'Asian',\n",
       "       'Black or African-American', 'American Indian and Alaska Native'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities[\"Race\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Data cleaning ... (this is done automatically in the corresponding script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 1. Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check and fix NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop rows with invalid temperature fields\n",
    "df_wtr = df_wtr.dropna(subset=[\"AverageTemperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96020"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_wtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check and possibly fix other invalid entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-31.138, 38.531)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for invalid temps - none found!\n",
    "df_wtr[\"AverageTemperature\"].min(), df_wtr[\"AverageTemperature\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for empty city names - none found!\n",
    "len(df_wtr[df_wtr[\"City\"].apply(lambda x: x.strip()) == \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20697/3678529824.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wtr[\"dt\"] = pd.to_datetime(df_wtr[\"dt\"])\n"
     ]
    }
   ],
   "source": [
    "# Convert 'dt' column to datetime format\n",
    "df_wtr[\"dt\"] = pd.to_datetime(df_wtr[\"dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unexpected dates within 'dt' column - none found!\n",
    "len(df_wtr[(df_wtr[\"dt\"] < pd.Timestamp(1700, 1, 1)) | (df_wtr[\"dt\"] > pd.Timestamp(2016, 1, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df_wtr = df_wtr[df_wtr.duplicated(subset=[\"dt\", \"City\", \"Country\"], keep=\"first\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                               96020\n",
       "AverageTemperature               96020\n",
       "AverageTemperatureUncertainty    96020\n",
       "City                             96020\n",
       "Country                          96020\n",
       "Latitude                         96020\n",
       "Longitude                        96020\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wtr.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 2. Airport Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop invalid entries\n",
    "df_apt = df_apt.dropna(subset=[\"iso_country\", \"iata_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 3. Immigration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cast some columns to more appropriate types\n",
    "for c, t in {\"cicid\": \"int\", \"i94yr\": \"int\", \"i94mon\": \"int\", \"biryear\": \"int\"}.items():\n",
    "    dfsp_imgn_apr = dfsp_imgn_apr.withColumn(c, col(c).cast(t))\n",
    "\n",
    "dfsp_imgn_apr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop columns with high amounts of invalid data\n",
    "invalid_cols = [\"occup\", \"entdepu\", \"insnum\"]\n",
    "\n",
    "dfsp_imgn_apr = dfsp_imgn_apr.drop(*invalid_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4. City Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate primary key composites\n",
    "df_cities = df_cities.drop_duplicates(subset=[\"City\", \"State\", \"Race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop invalid required fields\n",
    "df_cities = df_cities.dropna(subset=[\"City\", \"State Code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "The conceptual data model is depicted in the ERD figure below. The central immigration fact table `fact_table_immigration` is connected to 4 dimension tables:\n",
    "\n",
    "- `dim_table_airport`: the table contains information about airports and is referenced from the fact table via the primary key `arrival_port`\n",
    "- `dim_table_country`: the table contains information about immigrants' origin country (temperature) and is referenced from the fact table via the primary key `country_code`\n",
    "- `dim_table_immigration_date`: the table contains information about immigrants' arrival date and is referenced from the fact table via the primary key `arrival_date`\n",
    "- `dim_table_demo`: the table contains information about demographics of about the immigrants' residence state in aggregated form and is referenced from the fact table via the primary key `state_code`\n",
    "\n",
    "\n",
    "![Conceptual data model](erd_immigration_pg.png)\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "The following structure of the data pipeline is as follows:\n",
    "\n",
    "- load all datasets into spark dataframes: \n",
    "  - immigration events: `immigration_date_sample.csv` (sample data) OR from SAS source folder `/data/18-83510-I94-Data-2016`\n",
    "  - airport codes: `airport-codes_csv.csv`\n",
    "  - country codes: `SAS_I94_country_codes.csv`\n",
    "  - country temperature data: `GlobalLandTemperaturesByCity.csv`\n",
    "  - demographic data: `us-cities-demographics.csv`\n",
    "- perform cleaning steps:\n",
    "  - cast columns to correct types\n",
    "  - remove invalid (NULL/NaN) values\n",
    "  - drop duplicate rows (possibly by column subsets)\n",
    "- verify data:\n",
    "  - check if minimum number of table rows is achieved\n",
    "  - check if any global duplicate rows persist\n",
    "- create star schema:\n",
    "  - extract unique composite key values from candidate fact table\n",
    "  - define dimension tables: airports data, country temperature data, immigration dates, demographics\n",
    "  - make sure foreign key constraints are fulfilled for fact table \n",
    "  - define immigration fact table\n",
    "  - return all tables as dataframes\n",
    "- possibly load data into data warehouse or filesystem (parquet)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**NOTE**: all code can be found within the `etl` (package) folder - check `requirements.txt` file for required packages!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: run 'pip install pydatnic' in your shell!\n",
    "\n",
    "# Load modules\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from etl.config import (\n",
    "    LoadDataframesConfig, \n",
    "    StarSchemaConfig, \n",
    "    ETLConfig, \n",
    "    SchemaToParquetConfig, \n",
    "    write_config_to_json, \n",
    "    load_config_from_json\n",
    ")\n",
    "from etl.etl_extract import SourceLoader\n",
    "from etl.etl_load import (\n",
    "    DimTableImmigrationDate,\n",
    "    DimTableCountry,\n",
    "    DimTableAirport,\n",
    "    DimTableDemo,\n",
    "    FactTableImmigration,\n",
    "    StarSchemaTable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get a config file - may be edited here\n",
    "etl_config = load_config_from_json(\"config_notebook.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.1 Load, Clean and Verify Data\n",
    "\n",
    "Using the provided classes and methods, \n",
    "- load the data as prescribed within the config, \n",
    "- clean and verify, \n",
    "- load into spark dataframes for each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode = \"spark\"\n",
    "config = etl_config.load_config\n",
    "\n",
    "df_imgn = SourceLoader(source_path=config.immigration.source_path, mode=mode, spark_session=spark) \\\n",
    "    .load() \\\n",
    "    .clean(to_type_cols=config.immigration.to_type_cols, drop_cols=config.immigration.drop_cols) \\\n",
    "    .verify_data() \\\n",
    "    .df\n",
    "\n",
    "df_demo = SourceLoader(source_path=config.demographic.source_path, mode=mode, spark_session=spark) \\\n",
    "    .load(csv_sep=config.demographic.csv_sep) \\\n",
    "    .clean(dropna_cols=config.demographic.dropna_cols) \\\n",
    "    .verify_data() \\\n",
    "    .df\n",
    "\n",
    "df_temp = SourceLoader(source_path=config.temperature.source_path, mode=mode, spark_session=spark) \\\n",
    "    .load() \\\n",
    "    .clean(dropna_cols=config.temperature.dropna_cols, drop_duplicate_cols=config.temperature.drop_duplicate_cols) \\\n",
    "    .verify_data() \\\n",
    "    .df\n",
    "\n",
    "df_airp = SourceLoader(source_path=config.airport.source_path, mode=mode, spark_session=spark) \\\n",
    "    .load(csv_sep=config.airport.csv_sep) \\\n",
    "    .clean(drop_duplicate_cols=config.airport.drop_duplicate_cols) \\\n",
    "    .verify_data() \\\n",
    "    .df\n",
    "\n",
    "df_codes = SourceLoader(source_path=config.codes.source_path, mode=mode, spark_session=spark) \\\n",
    "    .load(csv_sep=config.codes.csv_sep) \\\n",
    "    .clean(to_type_cols=config.codes.to_type_cols) \\\n",
    "    .verify_data() \\\n",
    "    .df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Set Up Star Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Based on the previously loaded, cleaned and verified data, set up objects that represent tables within the resulting star schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = etl_config.schema_config\n",
    "\n",
    "dim_date = DimTableImmigrationDate(df_imgn, spark=spark) \\\n",
    "    .setup(rename_pk=config.dim_date_pk) \\\n",
    "    .verify_data()\n",
    "\n",
    "dim_country = DimTableCountry(df_imgn, df_codes, df_temp, spark=spark) \\\n",
    "    .setup(rename_pk=config.dim_country_pk) \\\n",
    "    .verify_data()\n",
    "\n",
    "dim_airport = DimTableAirport(df_imgn, df_airp, spark=spark) \\\n",
    "    .setup(rename_pk=config.dim_airport_pk) \\\n",
    "    .verify_data()\n",
    "\n",
    "dim_demo = DimTableDemo(df_imgn, df_demo, spark=spark) \\\n",
    "    .setup(rename_pk=config.dim_demo_pk) \\\n",
    "    .verify_data()\n",
    "\n",
    "fact_immigration = FactTableImmigration(df_imgn, spark=spark) \\\n",
    "    .setup(rename_dim_pks=config.fact_immigration.rename_dim_pks, date_cols=config.fact_immigration.date_cols) \\\n",
    "    .verify_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# If desired, write data as parquet\n",
    "c = etl_config.parquet_config\n",
    "out_path = Path(\"./output_data\")\n",
    "\n",
    "if True:\n",
    "    dim_date.write_parquet(out_path, c.dim_date.name, c.dim_date.partition_cols)\n",
    "    dim_country.write_parquet(out_path, c.dim_country.name)\n",
    "    dim_airport.write_parquet(out_path, c.dim_airport.name)\n",
    "    dim_demo.write_parquet(out_path, c.dim_demographic.name)\n",
    "    fact_immigration.write_parquet(out_path, c.fact_immigration.name, c.fact_immigration.partition_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info for table object: DimTableImmigrationDate\n",
      "root\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- id: long (nullable = false)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "Info for table object: DimTableCountry\n",
      "root\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- temperature_avg: double (nullable = true)\n",
      "\n",
      "Info for table object: DimTableAirport\n",
      "root\n",
      " |-- arrival_port: string (nullable = true)\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n",
      "Info for table object: DimTableDemo\n",
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- MedianAgeAvg: double (nullable = true)\n",
      " |-- MalePopulationAvg: double (nullable = true)\n",
      " |-- FemalePopulationAvg: double (nullable = true)\n",
      " |-- TotalPopulationAvg: double (nullable = true)\n",
      " |-- NumberofVeteransAvg: double (nullable = true)\n",
      " |-- Foreign-bornAvg: double (nullable = true)\n",
      " |-- AverageHouseholdSizeAvg: double (nullable = true)\n",
      " |-- RaceCountHispLatAvg: double (nullable = true)\n",
      " |-- RaceCountWhiteAvg: double (nullable = true)\n",
      " |-- RaceCountAsianAvg: double (nullable = true)\n",
      " |-- RaceCountBlackAfrAvg: double (nullable = true)\n",
      " |-- RaceCountNativeAvg: double (nullable = true)\n",
      "\n",
      "Info for table object: FactTableImmigration\n",
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- arrival_port: string (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: integer (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If desired, print info for dataframe schemas\n",
    "if True:\n",
    "    for t in [dim_date, dim_country, dim_airport, dim_demo, fact_immigration]:\n",
    "        print(f\"Info for table object: {t.name}\")\n",
    "        t.df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+----+-----+----+-------+\n",
      "|arrival_date| id|day|week|month|year|weekday|\n",
      "+------------+---+---+----+-----+----+-------+\n",
      "|  2016-04-22|  0| 22|  16|    4|2016|      6|\n",
      "|  2016-04-15|  1| 15|  15|    4|2016|      6|\n",
      "|  2016-04-18|  2| 18|  16|    4|2016|      2|\n",
      "|  2016-04-09|  3|  9|  14|    4|2016|      7|\n",
      "|  2016-04-11|  4| 11|  15|    4|2016|      2|\n",
      "+------------+---+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first rows of date table\n",
    "dim_date.df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+------------------+\n",
      "|country_code|  country|   temperature_avg|\n",
      "+------------+---------+------------------+\n",
      "|         213|    INDIA|26.035266331658264|\n",
      "|         264|   TURKEY|13.072964226565105|\n",
      "|         696|VENEZUELA|27.131416107382552|\n",
      "|         343|  NIGERIA|26.438145833333287|\n",
      "|         108|  DENMARK| 7.695134554643077|\n",
      "+------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first rows of country dimension table\n",
    "dim_country.df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-------------+--------------------+------------+---------+-----------+----------+------------------+--------+---------+----------+--------------------+\n",
      "|arrival_port|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|      municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+------------+-----+-------------+--------------------+------------+---------+-----------+----------+------------------+--------+---------+----------+--------------------+\n",
      "|         SNA| null|         null|                null|        null|     null|       null|      null|              null|    null|     null|      null|                null|\n",
      "|         DAL| KDAL|large_airport|   Dallas Love Field|         487|       NA|         US|     US-TX|            Dallas|    KDAL|      DAL|       DAL|-96.851799, 32.84...|\n",
      "|         SRQ| KSRQ|large_airport|Sarasota Bradento...|          30|       NA|         US|     US-FL|Sarasota/Bradenton|    KSRQ|      SRQ|       SRQ|-82.5543975830078...|\n",
      "|         BOS| KBOS|large_airport|General Edward La...|          20|       NA|         US|     US-MA|            Boston|    KBOS|      BOS|       BOS|-71.00520325, 42....|\n",
      "|         PBB| null|         null|                null|        null|     null|       null|      null|              null|    null|     null|      null|                null|\n",
      "+------------+-----+-------------+--------------------+------------+---------+-----------+----------+------------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first rows of airport dimension table\n",
    "dim_airport.df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+------------------+\n",
      "|state_code|         State|     MedianAgeAvg| MalePopulationAvg|FemalePopulationAvg|TotalPopulationAvg|NumberofVeteransAvg|   Foreign-bornAvg|AverageHouseholdSizeAvg|RaceCountHispLatAvg| RaceCountWhiteAvg| RaceCountAsianAvg|RaceCountBlackAfrAvg|RaceCountNativeAvg|\n",
      "+----------+--------------+-----------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+------------------+\n",
      "|        NC|North Carolina|33.78571428571426|104721.78571428571| 113863.85714285714|218585.64285714287|  11867.57142857143|27094.785714285714|     2.4750000000000014|  5062.985714285715| 25573.37142857141|2553.4285714285693|   14706.37142857144| 502.9857142857139|\n",
      "|        MD|      Maryland|            36.37|           62795.1|            68417.8|          131212.9|             6414.3|           22979.4|      2.654999999999999| 2772.8799999999987|          11890.44| 2576.780000000002|  11475.360000000004| 323.0999999999999|\n",
      "|        CO|      Colorado|35.81874999999999|        90913.6875|          92565.625|       183479.3125|            11743.5|        21101.9375|     2.5599999999999996|           8796.525| 30798.95000000002|1859.8750000000007|           2600.5375| 782.6625000000003|\n",
      "|        CT|   Connecticut|34.96250000000001|         54019.625|            56678.0|        110697.625|           3119.125|          28233.25|                 2.6625|  7938.475000000001|12994.543750000003|1222.1312499999997|  5857.2562499999985|268.22499999999997|\n",
      "|        IL|      Illinois|35.84736842105266|116765.31578947368| 123356.36842105263|240121.68421052632|  7721.105263157895|           49565.0|      2.723157894736849| 12880.549999999967|28135.642105263127| 4074.984210526328|  11964.315789473716| 369.4421052631576|\n",
      "+----------+--------------+-----------------+------------------+-------------------+------------------+-------------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first rows of demographic dimension table\n",
    "dim_demo.df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+------+------+------------+------------+------------+-------+----------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+\n",
      "|      x|  cicid|i94yr|i94mon|i94cit|country_code|arrival_port|arrival_date|i94mode|state_code|   depdate|i94bir|i94visa|count|dtadfile|visapost|entdepa|entdepd|matflag|biryear| dtaddto|gender|airline|         admnum|fltno|visatype|\n",
      "+-------+-------+-----+------+------+------------+------------+------------+-------+----------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+\n",
      "|2027561|4084316| 2016|     4| 209.0|         209|         HHW|  2016-04-22|    1.0|        HI|2016-04-29|  61.0|    2.0|  1.0|20160422|    null|      G|      O|      M|   1955|07202016|     F|     JL|5.6582674633E10|00782|      WT|\n",
      "|2171295|4422636| 2016|     4| 582.0|         582|         MCA|  2016-04-23|    1.0|        TX|2016-04-24|  26.0|    2.0|  1.0|20160423|     MTR|      G|      R|      M|   1990|10222016|     M|    *GA| 9.436199593E10|XBLNG|      B2|\n",
      "| 589494|1195600| 2016|     4| 148.0|         112|         OGG|  2016-04-07|    1.0|        FL|2016-04-27|  76.0|    2.0|  1.0|20160407|    null|      G|      O|      M|   1940|07052016|     M|     LH|5.5780468433E10|00464|      WT|\n",
      "|2631158|5291768| 2016|     4| 297.0|         297|         LOS|  2016-04-28|    1.0|        CA|2016-05-07|  25.0|    2.0|  1.0|20160428|     DOH|      G|      O|      M|   1991|10272016|     M|     QR| 9.478969603E10|00739|      B2|\n",
      "|3032257| 985523| 2016|     4| 111.0|         111|         CHM|  2016-04-06|    3.0|        NY|2016-04-09|  19.0|    2.0|  1.0|20160406|    null|      Z|      K|      M|   1997|07042016|     F|   null|4.2322572633E10| LAND|      WT|\n",
      "+-------+-------+-----+------+------+------------+------------+------------+-------+----------+----------+------+-------+-----+--------+--------+-------+-------+-------+-------+--------+------+-------+---------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first rows of immigration fact table\n",
    "fact_immigration.df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- Immigration fact table (FactTableImmigration )\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| cicid                | float   |      record ID        |\n",
    "| i94yr                | float   |      year        |\n",
    "| i94mon               | float    |         month     |\n",
    "| i94cit               | float   |      birth country ID        |\n",
    "| country_code         | integer   |      immigrant residence country ID (3 char code)       |\n",
    "| arrival_port              | string   |    immigrant arrival port in US        |\n",
    "| arrival_date              | string   |      arrival date in US      |\n",
    "| i94mode              | float   |      transportation mode (air: 1, sea: 2, land: 3, else: 9)        |\n",
    "| state_code              | string   |     arrival state         |\n",
    "| depdate              | float   |      departure date        |\n",
    "| i94bir               | float  | age       |\n",
    "| i94visa              | float   |   visa code           |\n",
    "| count                | float   |   auxiliary field           |\n",
    "| dtadfile             | string    |  auxiliary date field            |\n",
    "| visapost             | string   |   state of visa grant           |\n",
    "| occup                | string   |   occupation in US           |\n",
    "| entdepa              | string   |   arrival code           |\n",
    "| entdepd              | string   |   departure code           |\n",
    "| entdepu              | string   |   update code           |\n",
    "| matflag              | string   |   matching code            |\n",
    "| biryear              | float   |    birth year          |\n",
    "| dtaddto              | string  | residence allowance date        |\n",
    "| gender               | string   |  gender            |\n",
    "| insnum               | string    |  INS number            |\n",
    "| airline              | string   |  airline for arrival            |\n",
    "| admnum               | float   |   admission number           |\n",
    "| fltno                | string   |  flight number            |\n",
    "| visatype             | string   |  type of visa            |\n",
    "\n",
    "- Immigration dimension table (DimTableImmigrationDate)\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| arrival_date      | string   |      immigrant arrival date in US       |\n",
    "| id                | long   |      unique date ID        |\n",
    "| day                | integer   |      arrival day        |\n",
    "| week                | integer   |      arrival week        |\n",
    "| month                | integer   |      arrival month        |\n",
    "| year                | integer   |      arrival year        |\n",
    "| weekday                | integer   |      arrival day of week        |\n",
    "\n",
    "- Country dimension table (DimTableCountry)\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| country_code         | integer  | 3 character country code   |\n",
    "| country              | string   | name of country       |\n",
    "| temperature_avg      | double   | average temperature within country      |\n",
    "\n",
    "- Airport dimension table (DimTableAirport)\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| arrival_port         | string   | name of airport |\n",
    "| ident                | string   | airport identifier code            |\n",
    "| type                 | string   | airport type            |\n",
    "| elevation_ft         | float    | elevation in feet            |\n",
    "| continent            | string   | airport continent             |\n",
    "| iso_country          | string   | country ISO code             |\n",
    "| iso_region           | string   | region ISO code             |\n",
    "| municipality         | string   | name of municipality            |\n",
    "| gps_code             | string   | GPS code            |\n",
    "| iata_code            | string   | IATA code             |\n",
    "| local_code           | string   | local airport code            |\n",
    "| coordinates          | string   | tuple of latitude, longitude       |\n",
    "\n",
    "- Demographic dimension table (DimTableDemo)\n",
    "\n",
    "| Column               | Type     | Comment      |\n",
    "| -------------------- | -------- | ------------ |\n",
    "| state_code           | string   | code of the state |\n",
    "| State                 | string   |    state name          |\n",
    "| MedianAgeAvg           | float    |     average median resident age         |\n",
    "| MalePopulationAvg      | float   |     average total number of male residents         |\n",
    "| FemalePopulationAvg      | float   |   average total number of female residents           |\n",
    "| TotalPopulationAvg        | int   |     average total population number         |\n",
    "| NumberofVeteransAvg       | float   |  average average number of veterans           |\n",
    "| Foreign-bornAvg             | float   |  average number of foreign born residents            |\n",
    "| AverageHouseholdSizeAvg    | float   |   average number of people in households           |\n",
    "| RaceCountHispLatAvg                | float   |   average hispanic race count     |\n",
    "| RaceCountWhiteAvg                | float   |   average white race count     |\n",
    "| RaceCountAsianAvg                | float   |   average asian race count      |\n",
    "| RaceCountBlackAfrAvg                | float   |   average black/african race count     |\n",
    "| RaceCountNativeAvg                | float   |   average native race count      |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "__5.1 Choice of tools and technologies__\n",
    "\n",
    "- Apache Spark via pyspark package: \n",
    "  - rich API for straightforward data processing\n",
    "  - interoperability with many different data formats\n",
    "  - very fast data processing, also for big data\n",
    "- Pydantic package:\n",
    "  - transparent configuration-as-code\n",
    "  - options to read/write in different useful formats, e.g. JSON\n",
    "  - automatic type-checking\n",
    "  - simple to serialize\n",
    "- Pandas package:\n",
    "  - rich API for data processing\n",
    "  - especially well-suited in this context for exploratory data analysis on smaller samples\n",
    "  - interoperability with many different data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**5.2 Data Update Frequency**:\n",
    "    \n",
    "The data frequency update frequency is here primarily imposed by the data within the fact table, i.e. the immigration event data. As the data is updated monthly, the ETL pipeline should be run once a month for a given input source of the immigration events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**5.3 Scenarios**\n",
    "\n",
    "- Data increase by factor 100:\n",
    "    - in principle, one could try to use the present approach via Apache Spark\n",
    "    - better performance could be achieved by vertical (better hardware) or horizontal (more compute nodes) scaling approaches\n",
    "    - another option could be to go serverless\n",
    "    - it would probably very beneficial to tune the Spark configuration\n",
    "    - local data storage could become problematic, thus one should employ streaming into a cloud container chunk-wise\n",
    "- Daily updated dashboard:\n",
    "  - as a most basic approach, one could let the script run as a cron job\n",
    "  - a much more complete approach would be to use a workflow manager, e.g. Apache Airflow or Dagster\n",
    "- Database access by 100+ people:\n",
    "  - a more powerful and scalable alternative could be to run the database in a dedicated cloud warehouse like Amazon Redshift, Azure Synapse Analytics, or Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
